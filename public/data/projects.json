[
    {
      "leftContent": {
        "title": "CRAG-MM Challenge",
        "subtitle": "MM-RAG/VLLM",
        "items": [
          "An MM-RAG QA system takes as input an image ùêº and a question ùëÑ, and outputs an answer ùê¥; the answer is generated by MM-LLMs according to information retrieved from external sources, combined with knowledge internalized in the model. A Multi-turn MM-RAG QA system, in addition, takes questions and answers from previous turns as context to answer new questions. The answer should provide useful information to answer the question without adding any hallucination.",
          "Simple questions: Questions asking for simple facts.",
          "Multi-hop questions: Questions that require chaining multiple pieces of information to compose the answer (e.g., \"What other movies have the director of this movie directed in the past?\").",
          "Comparison and Aggregation questions: Questions requiring aggregating or comparing multiple pieces of information (e.g., \"Which drinks do not contain added sugar among these?\" or \"Is this cheaper on Amazon?\").",
          "Reasoning questions: Questions about an entity that cannot be directly looked up and require reasoning to answer (e.g., \"Can the dryer be used in Europe?\" where the image shows a dryer)."
        ]
      },
      "images": [
        {
          "src": "/images/MM-RAG.png",
          "alt": "MM-RAG Illustration",
          "url":"https://www.aicrowd.com/challenges/meta-crag-mm-challenge-2025"
        }
      ],
      "status": "ongoing"
    },
    {
      "leftContent": {
        "title": "Application of RAG and LLM in Financial Q&A",
        "subtitle": "LLM/RAG/Deep Learning/Pytorch",
        "items": [
          "Integrated LLM and Retrieval-Augmented Generation (RAG) techniques to develop an effective Financial Q&A model",
          "Fine-tuned the Multilingual retriever and BAAI reranker within a RAG framework, optimizing the retrieval process to provide the most relevant answers from the question documents",
          "Achieved 89.37% accuracy on a contest dataset of 900 questions, ranking 42nd out of 487 participants, placing in the top 8%"
        ]
      },
      "images": [
        {
          "src": "/images/RAG_architecture.png",
          "alt": "RAG Illustration",
          "url":"https://github.com/NicksonCheng/AIcup2024_RAG"
        },
        {
          "src": "/images/RAG_score.png",
          "alt": "RAG score",
          "url":"https://github.com/NicksonCheng/AIcup2024_RAG"
        }
      ],
      "status": "finished"
    },
    {
      "leftContent": {
        "title": "R-Tree Based Lost Pet Locator",
        "subtitle": "R-Tree/React Native/Node.js/Expo",
        "items": [
          "Implemented the R-Tree algorithm to optimize the search and management of geospatial data for tracking lost pet",
          "Developed full-stack application using React Native and Node.js, integrating R-Tree for efficient and seamless functionality",
          "Used Expo to deploy universal native apps for Android and iOS, streamlining both development and deployment"
        ]
      },
      "images": [
        {
          "src": "/images/RTree_framwork.png",
          "alt": "framwork",
          "url":""
        },
        {
          "src": "/images/RTree.png",
          "alt": "R-Tree",
          "url":""
        },
        {
          "src": "/images/RTree_advance.png",
          "alt": "R-tree advance",
          "url":""
        }
      ],
      "status": "finished"
    }
  ]